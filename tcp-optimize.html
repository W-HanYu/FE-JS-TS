<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.51">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>如何优化 TCP? | </title><meta name="description" content="">
    <link rel="modulepreload" href="/assets/app.10857eea.js"><link rel="modulepreload" href="/assets/tcp-optimize.html.bdddfd5b.js"><link rel="modulepreload" href="/assets/tcp-optimize.html.4370769b.js"><link rel="prefetch" href="/assets/1.1.hello-world.html.64e999cb.js"><link rel="prefetch" href="/assets/1.10.if.html.943cdf0c.js"><link rel="prefetch" href="/assets/1.11.includes.html.571e5f8c.js"><link rel="prefetch" href="/assets/1.12.parameters.html.564dfc8c.js"><link rel="prefetch" href="/assets/1.13.push.html.b72bad70.js"><link rel="prefetch" href="/assets/1.14.unshift.html.3d0b1ac3.js"><link rel="prefetch" href="/assets/1.2.Pick.html.1cf0b401.js"><link rel="prefetch" href="/assets/1.3.Awaited.html.85e83850.js"><link rel="prefetch" href="/assets/1.4.Readonly.html.512547f5.js"><link rel="prefetch" href="/assets/1.5.Tuple-to-object.html.f9930299.js"><link rel="prefetch" href="/assets/1.6.First-of-array.html.b0696427.js"><link rel="prefetch" href="/assets/1.7.Length-of-Tuple.html.06336084.js"><link rel="prefetch" href="/assets/1.8.concat.html.c900e85e.js"><link rel="prefetch" href="/assets/1.9.exclude.html.3d9c9834.js"><link rel="prefetch" href="/assets/2.1.Get-Return-Type.html.1b889bcc.js"><link rel="prefetch" href="/assets/2.2.omit.html.20d83bcf.js"><link rel="prefetch" href="/assets/2.3.Readonly2.html.031c531b.js"><link rel="prefetch" href="/assets/2.4.Deep-Readonly.html.7fde66b5.js"><link rel="prefetch" href="/assets/2.5.turn-to-union.html.af1c2948.js"><link rel="prefetch" href="/assets/3.1.Simple-Vue.html.3007ed82.js"><link rel="prefetch" href="/assets/basic-1.html.57108e15.js"><link rel="prefetch" href="/assets/basic-2.html.b238470b.js"><link rel="prefetch" href="/assets/basic-3.html.1a2b8e1b.js"><link rel="prefetch" href="/assets/http-2.html.35c8ed2a.js"><link rel="prefetch" href="/assets/http-3.html.1e314715.js"><link rel="prefetch" href="/assets/http-interview.html.4bb6817e.js"><link rel="prefetch" href="/assets/http-optimize.html.6d2d3508.js"><link rel="prefetch" href="/assets/http-rpc.html.5f76b948.js"><link rel="prefetch" href="/assets/http-websocket.html.59ef70c5.js"><link rel="prefetch" href="/assets/https-ecdhe.html.8c1f5f63.js"><link rel="prefetch" href="/assets/https-optimize.html.5758cdcd.js"><link rel="prefetch" href="/assets/https-rsa.html.2191d477.js"><link rel="prefetch" href="/assets/ip-base.html.7af4058e.js"><link rel="prefetch" href="/assets/ip-ping.html.3431e393.js"><link rel="prefetch" href="/assets/ip-ping_io.html.1d01cf43.js"><link rel="prefetch" href="/assets/tcp-challenge-ack.html.4dc1810d.js"><link rel="prefetch" href="/assets/tcp-dump.html.e58a0c7c.js"><link rel="prefetch" href="/assets/tcp-feature.html.2396dace.js"><link rel="prefetch" href="/assets/tcp-interview.html.30af561a.js"><link rel="prefetch" href="/assets/tcp-isn-deff.html.743a32bd.js"><link rel="prefetch" href="/assets/tcp-out-of-order-fin.html.5044867e.js"><link rel="prefetch" href="/assets/tcp-queue.html.77e274c7.js"><link rel="prefetch" href="/assets/tcp-stream.html.83c63ce4.js"><link rel="prefetch" href="/assets/tcp-syn.html.96c19b66.js"><link rel="prefetch" href="/assets/donate.html.d9928a63.js"><link rel="prefetch" href="/assets/Routine1_pattern-matching-for-extraction.html.304b153a.js"><link rel="prefetch" href="/assets/Advanced-1.html.353f6c87.js"><link rel="prefetch" href="/assets/Advanced-2.html.88bb5264.js"><link rel="prefetch" href="/assets/Advanced-3.html.96bb2cc6.js"><link rel="prefetch" href="/assets/Advanced-4.html.3ca80786.js"><link rel="prefetch" href="/assets/Advanced-5.html.c867a8f0.js"><link rel="prefetch" href="/assets/Extended-article-1.html.6c21c6c7.js"><link rel="prefetch" href="/assets/base-1.html.502a2ddb.js"><link rel="prefetch" href="/assets/base-10.html.6a577a2f.js"><link rel="prefetch" href="/assets/base-11.html.ba242773.js"><link rel="prefetch" href="/assets/base-12.html.bf38defb.js"><link rel="prefetch" href="/assets/base-13.html.e2815939.js"><link rel="prefetch" href="/assets/base-14.html.91f5ff1a.js"><link rel="prefetch" href="/assets/base-15.html.17167a0d.js"><link rel="prefetch" href="/assets/base-16.html.8107a224.js"><link rel="prefetch" href="/assets/base-17.html.88056264.js"><link rel="prefetch" href="/assets/base-2.html.2bd656bb.js"><link rel="prefetch" href="/assets/base-3.html.57130013.js"><link rel="prefetch" href="/assets/base-4.html.52612b71.js"><link rel="prefetch" href="/assets/base-5.html.8f5804c6.js"><link rel="prefetch" href="/assets/base-6.html.676fd870.js"><link rel="prefetch" href="/assets/base-7.html.c35649b2.js"><link rel="prefetch" href="/assets/base-8.html.f62a44d6.js"><link rel="prefetch" href="/assets/base-9.html.e15334be.js"><link rel="prefetch" href="/assets/rollup-1.html.a0e88271.js"><link rel="prefetch" href="/assets/rollup-10.html.d7457140.js"><link rel="prefetch" href="/assets/rollup-11.html.387a1d50.js"><link rel="prefetch" href="/assets/rollup-2.html.272f10b1.js"><link rel="prefetch" href="/assets/rollup-3.html.3bfd8692.js"><link rel="prefetch" href="/assets/rollup-4.html.56636c64.js"><link rel="prefetch" href="/assets/rollup-5.html.11f34699.js"><link rel="prefetch" href="/assets/rollup-6.html.626d4ddb.js"><link rel="prefetch" href="/assets/rollup-7.html.560b9cf5.js"><link rel="prefetch" href="/assets/rollup-8.html.97dd433f.js"><link rel="prefetch" href="/assets/rollup-9.html.1d3a455c.js"><link rel="prefetch" href="/assets/scope-closures-appA.html.fe38f021.js"><link rel="prefetch" href="/assets/scope-closures-appB.html.8b005e05.js"><link rel="prefetch" href="/assets/scope-closures-appC.html.081c0336.js"><link rel="prefetch" href="/assets/this-object-prototype-appA.html.7018895f.js"><link rel="prefetch" href="/assets/async-performance-apA.html.3ca37a19.js"><link rel="prefetch" href="/assets/async-performance-apB.html.a8593452.js"><link rel="prefetch" href="/assets/async-performance-ch1.html.f52ab151.js"><link rel="prefetch" href="/assets/async-performance-ch2.html.75e5e133.js"><link rel="prefetch" href="/assets/async-performance-ch3.html.9dc2d68e.js"><link rel="prefetch" href="/assets/async-performance-ch4.html.240640d5.js"><link rel="prefetch" href="/assets/async-performance-ch5.html.25a5f200.js"><link rel="prefetch" href="/assets/async-performance-ch6.html.d865cab7.js"><link rel="prefetch" href="/assets/types-grammar-1.html.3a0001f4.js"><link rel="prefetch" href="/assets/types-grammar-2.html.ae03c918.js"><link rel="prefetch" href="/assets/types-grammar-3.html.1aefd5a9.js"><link rel="prefetch" href="/assets/types-grammar-4.html.8ce8557b.js"><link rel="prefetch" href="/assets/types-grammar-5.html.dc3bb8a0.js"><link rel="prefetch" href="/assets/types-grammar-apA.html.b06bd67a.js"><link rel="prefetch" href="/assets/404.html.d2dc3323.js"><link rel="prefetch" href="/assets/1.1.hello-world.html.42e63562.js"><link rel="prefetch" href="/assets/1.10.if.html.29947578.js"><link rel="prefetch" href="/assets/1.11.includes.html.6439af8c.js"><link rel="prefetch" href="/assets/1.12.parameters.html.f743e93e.js"><link rel="prefetch" href="/assets/1.13.push.html.d381f6e4.js"><link rel="prefetch" href="/assets/1.14.unshift.html.f7697a1b.js"><link rel="prefetch" href="/assets/1.2.Pick.html.5c8b261a.js"><link rel="prefetch" href="/assets/1.3.Awaited.html.00167622.js"><link rel="prefetch" href="/assets/1.4.Readonly.html.4fb48369.js"><link rel="prefetch" href="/assets/1.5.Tuple-to-object.html.0580b17a.js"><link rel="prefetch" href="/assets/1.6.First-of-array.html.2a8e2362.js"><link rel="prefetch" href="/assets/1.7.Length-of-Tuple.html.22ef7a18.js"><link rel="prefetch" href="/assets/1.8.concat.html.00c48e5c.js"><link rel="prefetch" href="/assets/1.9.exclude.html.9ad334e4.js"><link rel="prefetch" href="/assets/2.1.Get-Return-Type.html.31b52d2c.js"><link rel="prefetch" href="/assets/2.2.omit.html.fa3119b1.js"><link rel="prefetch" href="/assets/2.3.Readonly2.html.64f6aa55.js"><link rel="prefetch" href="/assets/2.4.Deep-Readonly.html.4e77227e.js"><link rel="prefetch" href="/assets/2.5.turn-to-union.html.e2d039fc.js"><link rel="prefetch" href="/assets/3.1.Simple-Vue.html.2b7f1073.js"><link rel="prefetch" href="/assets/basic-1.html.9c7edcc0.js"><link rel="prefetch" href="/assets/basic-2.html.8f694f24.js"><link rel="prefetch" href="/assets/basic-3.html.21ccd2e6.js"><link rel="prefetch" href="/assets/http-2.html.c1fb6ec6.js"><link rel="prefetch" href="/assets/http-3.html.c5a63bbe.js"><link rel="prefetch" href="/assets/http-interview.html.9564e879.js"><link rel="prefetch" href="/assets/http-optimize.html.9aeae060.js"><link rel="prefetch" href="/assets/http-rpc.html.e910cca5.js"><link rel="prefetch" href="/assets/http-websocket.html.eabf2195.js"><link rel="prefetch" href="/assets/https-ecdhe.html.4bd399d3.js"><link rel="prefetch" href="/assets/https-optimize.html.9fa887e8.js"><link rel="prefetch" href="/assets/https-rsa.html.b6695c4c.js"><link rel="prefetch" href="/assets/ip-base.html.88864407.js"><link rel="prefetch" href="/assets/ip-ping.html.b4d2cf0d.js"><link rel="prefetch" href="/assets/ip-ping_io.html.d9be93c0.js"><link rel="prefetch" href="/assets/tcp-challenge-ack.html.aec13b10.js"><link rel="prefetch" href="/assets/tcp-dump.html.5054c0a0.js"><link rel="prefetch" href="/assets/tcp-feature.html.e5f8705a.js"><link rel="prefetch" href="/assets/tcp-interview.html.5d5ed84e.js"><link rel="prefetch" href="/assets/tcp-isn-deff.html.50713709.js"><link rel="prefetch" href="/assets/tcp-out-of-order-fin.html.44ca7d32.js"><link rel="prefetch" href="/assets/tcp-queue.html.f96f1ac8.js"><link rel="prefetch" href="/assets/tcp-stream.html.f50b922c.js"><link rel="prefetch" href="/assets/tcp-syn.html.d4e27147.js"><link rel="prefetch" href="/assets/donate.html.5f5ee7cc.js"><link rel="prefetch" href="/assets/Routine1_pattern-matching-for-extraction.html.88e65250.js"><link rel="prefetch" href="/assets/Advanced-1.html.bd965a69.js"><link rel="prefetch" href="/assets/Advanced-2.html.ed37106b.js"><link rel="prefetch" href="/assets/Advanced-3.html.f637c11b.js"><link rel="prefetch" href="/assets/Advanced-4.html.13461ce2.js"><link rel="prefetch" href="/assets/Advanced-5.html.302a61c3.js"><link rel="prefetch" href="/assets/Extended-article-1.html.5b418970.js"><link rel="prefetch" href="/assets/base-1.html.b28e0e4f.js"><link rel="prefetch" href="/assets/base-10.html.db4a2b18.js"><link rel="prefetch" href="/assets/base-11.html.2dbfcb2c.js"><link rel="prefetch" href="/assets/base-12.html.9d00161a.js"><link rel="prefetch" href="/assets/base-13.html.e68063f5.js"><link rel="prefetch" href="/assets/base-14.html.448b967d.js"><link rel="prefetch" href="/assets/base-15.html.1877967e.js"><link rel="prefetch" href="/assets/base-16.html.1196549a.js"><link rel="prefetch" href="/assets/base-17.html.786ede5c.js"><link rel="prefetch" href="/assets/base-2.html.1a77f5e3.js"><link rel="prefetch" href="/assets/base-3.html.8d411cba.js"><link rel="prefetch" href="/assets/base-4.html.3cf75c04.js"><link rel="prefetch" href="/assets/base-5.html.75cba69b.js"><link rel="prefetch" href="/assets/base-6.html.e2f1d2a2.js"><link rel="prefetch" href="/assets/base-7.html.1a7bea3f.js"><link rel="prefetch" href="/assets/base-8.html.f98cc478.js"><link rel="prefetch" href="/assets/base-9.html.5f235b4f.js"><link rel="prefetch" href="/assets/rollup-1.html.068a143d.js"><link rel="prefetch" href="/assets/rollup-10.html.ac1b5d1d.js"><link rel="prefetch" href="/assets/rollup-11.html.0eb72a05.js"><link rel="prefetch" href="/assets/rollup-2.html.7f877d86.js"><link rel="prefetch" href="/assets/rollup-3.html.9db7ab19.js"><link rel="prefetch" href="/assets/rollup-4.html.03417866.js"><link rel="prefetch" href="/assets/rollup-5.html.6bf2ac07.js"><link rel="prefetch" href="/assets/rollup-6.html.f60dcba5.js"><link rel="prefetch" href="/assets/rollup-7.html.43d61667.js"><link rel="prefetch" href="/assets/rollup-8.html.800da36b.js"><link rel="prefetch" href="/assets/rollup-9.html.611f6880.js"><link rel="prefetch" href="/assets/scope-closures-appA.html.74216843.js"><link rel="prefetch" href="/assets/scope-closures-appB.html.70010aba.js"><link rel="prefetch" href="/assets/scope-closures-appC.html.63cec5a0.js"><link rel="prefetch" href="/assets/this-object-prototype-appA.html.8185c311.js"><link rel="prefetch" href="/assets/async-performance-apA.html.3a4bf124.js"><link rel="prefetch" href="/assets/async-performance-apB.html.87add98c.js"><link rel="prefetch" href="/assets/async-performance-ch1.html.0ab91e47.js"><link rel="prefetch" href="/assets/async-performance-ch2.html.21b1e563.js"><link rel="prefetch" href="/assets/async-performance-ch3.html.a1d122a3.js"><link rel="prefetch" href="/assets/async-performance-ch4.html.0be79629.js"><link rel="prefetch" href="/assets/async-performance-ch5.html.40c03aff.js"><link rel="prefetch" href="/assets/async-performance-ch6.html.267fc5f0.js"><link rel="prefetch" href="/assets/types-grammar-1.html.21f879fa.js"><link rel="prefetch" href="/assets/types-grammar-2.html.191d3b5d.js"><link rel="prefetch" href="/assets/types-grammar-3.html.6156f983.js"><link rel="prefetch" href="/assets/types-grammar-4.html.78ab5f14.js"><link rel="prefetch" href="/assets/types-grammar-5.html.6c58e8d6.js"><link rel="prefetch" href="/assets/types-grammar-apA.html.90bd1ed7.js"><link rel="prefetch" href="/assets/404.html.8eda9d50.js">
    <link rel="stylesheet" href="/assets/style.f4d22aab.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/" class=""><!----><!--v-if--></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><!----><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><!----><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">如何优化 TCP? <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#tcp-三次握手的性能提升" class="router-link-active router-link-exact-active sidebar-item" aria-label="TCP 三次握手的性能提升"><!--[--><!--]--> TCP 三次握手的性能提升 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#客户端优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="客户端优化"><!--[--><!--]--> 客户端优化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#服务端优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="服务端优化"><!--[--><!--]--> 服务端优化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#如何绕过三次握手" class="router-link-active router-link-exact-active sidebar-item" aria-label="如何绕过三次握手？"><!--[--><!--]--> 如何绕过三次握手？ <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#小结" class="router-link-active router-link-exact-active sidebar-item" aria-label="小结"><!--[--><!--]--> 小结 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#tcp-四次挥手的性能提升" class="router-link-active router-link-exact-active sidebar-item" aria-label="TCP 四次挥手的性能提升"><!--[--><!--]--> TCP 四次挥手的性能提升 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#主动方的优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="主动方的优化"><!--[--><!--]--> 主动方的优化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#被动方的优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="被动方的优化"><!--[--><!--]--> 被动方的优化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#小结-1" class="router-link-active router-link-exact-active sidebar-item" aria-label="小结"><!--[--><!--]--> 小结 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#tcp-传输数据的性能提升" class="router-link-active router-link-exact-active sidebar-item" aria-label="TCP 传输数据的性能提升"><!--[--><!--]--> TCP 传输数据的性能提升 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#滑动窗口是如何影响传输速度的" class="router-link-active router-link-exact-active sidebar-item" aria-label="滑动窗口是如何影响传输速度的？"><!--[--><!--]--> 滑动窗口是如何影响传输速度的？ <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#如何确定最大传输速度" class="router-link-active router-link-exact-active sidebar-item" aria-label="如何确定最大传输速度？"><!--[--><!--]--> 如何确定最大传输速度？ <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#怎样调整缓冲区大小" class="router-link-active router-link-exact-active sidebar-item" aria-label="怎样调整缓冲区大小？"><!--[--><!--]--> 怎样调整缓冲区大小？ <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#小结-2" class="router-link-active router-link-exact-active sidebar-item" aria-label="小结"><!--[--><!--]--> 小结 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/graphicalNetwork/tcp-optimize.html#读者问答" class="router-link-active router-link-exact-active sidebar-item" aria-label="读者问答"><!--[--><!--]--> 读者问答 <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="如何优化-tcp" tabindex="-1"><a class="header-anchor" href="#如何优化-tcp" aria-hidden="true">#</a> 如何优化 TCP?</h1><p>TCP 性能的提升不仅考察 TCP 的理论知识，还考察了对于操作系统提供的内核参数的理解与应用。</p><p>TCP 协议是由操作系统实现，所以操作系统提供了不少调节 TCP 的参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/2.jpg" alt="Linux TCP 参数"></p><p>如何正确有效的使用这些参数，来提高 TCP 性能是一个不那么简单事情。我们需要针对 TCP 每个阶段的问题来对症下药，而不是病急乱投医。</p><p>接下来，将以三个角度来阐述提升 TCP 的策略，分别是：</p><ul><li>TCP 三次握手的性能提升；</li><li>TCP 四次挥手的性能提升；</li><li>TCP 数据传输的性能提升；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/3.jpg" alt="本节提纲"></p><hr><h2 id="tcp-三次握手的性能提升" tabindex="-1"><a class="header-anchor" href="#tcp-三次握手的性能提升" aria-hidden="true">#</a> TCP 三次握手的性能提升</h2><p>TCP 是面向连接的、可靠的、双向传输的传输层通信协议，所以在传输数据之前需要经过三次握手才能建立连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/4.jpg" alt="三次握手与数据传输"></p><p>那么，三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。</p><p>如何正确有效的使用这些参数，来提高 TCP 三次握手的性能，这就需要理解「三次握手的状态变迁」，这样当出现问题时，先用 <code>netstat</code> 命令查看是哪个握手阶段出现了问题，再来对症下药，而不是病急乱投医。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/5.jpg" alt="TCP 三次握手的状态变迁"></p><p>客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。</p><p>所以，客户端（主动发起连接方）和服务端（被动连接方）优化的方式是不同的，接下来分别针对客户端和服务端优化。</p><h3 id="客户端优化" tabindex="-1"><a class="header-anchor" href="#客户端优化" aria-hidden="true">#</a> 客户端优化</h3><p>三次握手建立连接的首要目的是「同步序列号」。</p><p>只有同步了序列号才有可靠传输，TCP 许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握手中的报文称为 SYN 的原因，SYN 的全称就叫 <em>Synchronize Sequence Numbers</em>（同步序列号）。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/6.jpg" alt="TCP 头部"></p><blockquote><p>SYN_SENT 状态的优化</p></blockquote><p>客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 <code>SYN_SENT</code> 状态。</p><p>客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包，<strong>重发的次数由 tcp_syn_retries 参数控制</strong>，默认是 5 次：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/7.jpg" alt=""></p><p>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，<strong>每次超时的时间是上一次的 2 倍</strong>。</p><p>当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就会终止三次握手。</p><p>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/8.jpg" alt="SYN 超时重传"></p><p>你可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。</p><h3 id="服务端优化" tabindex="-1"><a class="header-anchor" href="#服务端优化" aria-hidden="true">#</a> 服务端优化</h3><p>当服务端收到 SYN 包后，服务端会立马回复 SYN+ACK 包，表明确认收到了客户端的序列号，同时也把自己的序列号发给对方。</p><p>此时，服务端出现了新连接，状态是 <code>SYN_RCV</code>。在这个状态下，Linux 内核就会建立一个「半连接队列」来维护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/9.jpg" alt="半连接队列与全连接队列"></p><p>SYN 攻击，攻击的是就是这个半连接队列。</p><blockquote><p>如何查看由于 SYN 半连接队列已满，而被丢弃连接的情况？</p></blockquote><p>我们可以通过该 <code>netstat -s</code> 命令给出的统计结果中， 可以得到由于半连接队列已满，引发的失败次数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/10.jpg" alt=""></p><p>上面输出的数值是<strong>累计值</strong>，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。<strong>隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象</strong>。</p><blockquote><p>如何调整 SYN 半连接队列大小？</p></blockquote><p>要想增大半连接队列，<strong>不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</strong></p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/11.jpg" alt=""></p><p>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/12.jpg" alt=""></p><p>最后，改变了如上这些参数后，要重启 Nginx 服务，因为 SYN 半连接队列和 accept 队列都是在 <code>listen()</code> 初始化的。</p><blockquote><p>如果 SYN 半连接队列已满，只能丢弃连接吗？</p></blockquote><p>并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>。</p><p>syncookies 的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/13.jpg" alt="开启 syncookies 功能"></p><p>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/14.jpg" alt=""></p><blockquote><p>SYN_RCV 状态的优化</p></blockquote><p>当客户端接收到服务器发来的 SYN+ACK 报文后，就会回复 ACK 给服务器，同时客户端连接状态从 SYN_SENT 转换为 ESTABLISHED，表示连接建立成功。</p><p>服务器端连接成功建立的时间还要再往后，等到服务端收到客户端的 ACK 后，服务端的连接状态才变为 ESTABLISHED。</p><p>如果服务器没有收到 ACK，就会重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态。</p><p>当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。<strong>修改重发次数的方法是，调整 tcp_synack_retries 参数</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/15.jpg" alt=""></p><p>tcp_synack_retries 的默认重试次数是 5 次，与客户端重传 SYN 类似，它的重传会经历 1、2、4、8、16 秒，最后一次重传后会继续等待 32 秒，如果服务端仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒。</p><p>服务器收到 ACK 后连接建立成功，此时，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</p><p>如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/16.jpg" alt=" accept 队列溢出"></p><blockquote><p>accept 队列已满，只能丢弃连接吗？</p></blockquote><p>丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。打开这一功能需要将 tcp_abort_on_overflow 参数设置为 1。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/17.jpg" alt=""></p><p>tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</p><ul><li>0 ：如果 accept 队列满了，那么 server 扔掉 client 发过来的 ack ；</li><li>1 ：如果 accept 队列满了，server 发送一个 <code>RST</code> 包给 client，表示废掉这个握手过程和这个连接；</li></ul><p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 <code>connection reset by peer</code> 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p><p>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。</p><p>举个例子，当 accept 队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，客户端进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，客户端的请求就会被多次「重发」。<strong>如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 accept 队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/18.jpg" alt="tcp_abort_on_overflow 为 0 可以应对突发流量"></p><p>所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。</p><blockquote><p>如何调整 accept 队列的长度呢？</p></blockquote><p>accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：</p><ul><li>somaxconn 是 Linux 内核的参数，默认值是 128，可以通过 <code>net.core.somaxconn</code> 来设置其值；</li><li>backlog 是 <code>listen(int sockfd, int backlog)</code> 函数中的 backlog 大小；</li></ul><p>Tomcat、Nginx、Apache 常见的 Web 服务的 backlog 默认值都是 511。</p><blockquote><p>如何查看服务端进程 accept 队列的长度？</p></blockquote><p>可以通过 <code>ss -ltn</code> 命令查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/19.jpg" alt=""></p><ul><li>Recv-Q：当前 accept 队列的大小，也就是当前已完成三次握手并等待服务端 <code>accept()</code> 的 TCP 连接；</li><li>Send-Q：accept 队列最大长度，上面的输出结果说明监听 8088 端口的 TCP 服务，accept 队列的最大长度为 128；</li></ul><blockquote><p>如何查看由于 accept 连接队列已满，而被丢弃的连接？</p></blockquote><p>当超过了 accept 连接队列，服务端则会丢掉后续进来的 TCP 连接，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/20.jpg" alt=""></p><p>上面看到的 41150 times ，表示 accept 队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话，说明 accept 连接队列偶尔满了。</p><p>如果持续不断地有连接因为 accept 队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</p><h3 id="如何绕过三次握手" tabindex="-1"><a class="header-anchor" href="#如何绕过三次握手" aria-hidden="true">#</a> 如何绕过三次握手？</h3><p>以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。</p><p>三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/21.jpg" alt="常规 HTTP 请求"></p><p>在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。</p><blockquote><p>接下来说说，TCP Fast Open 功能的工作方式。</p></blockquote><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/22.jpg" alt="开启 TCP Fast Open 功能"></p><p>在客户端首次建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</li><li>支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；</li><li>客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</li></ol><p>所以，第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。</p><p>之后，如果客户端再次向服务器建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含「数据」（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 Cookie；</li><li>支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</li><li>如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，<strong>这就减少了握手带来的 1 个 RTT 的时间消耗</strong>；</li><li>客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；</li><li>此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。</li></ol><p>所以，之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗。</p><p>开启了 TFO 功能，cookie 的值是存放到 TCP option 字段里的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/TCP option字段 - TFO.png" alt="TCP option 字段 - TFO"></p><p>注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）。</p><blockquote><p>Linux 下怎么打开 TCP Fast Open 功能呢？</p></blockquote><p>在 Linux 系统中，可以通过<strong>设置 tcp_fastopn 内核参数，来打开 Fast Open 功能</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/23.jpg" alt=""></p><p>tcp_fastopn 各个值的意义:</p><ul><li>0 关闭</li><li>1 作为客户端使用 Fast Open 功能</li><li>2 作为服务端使用 Fast Open 功能</li><li>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</li></ul><p><strong>TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。</strong></p><h3 id="小结" tabindex="-1"><a class="header-anchor" href="#小结" aria-hidden="true">#</a> 小结</h3><p>本小结主要介绍了关于优化 TCP 三次握手的几个 TCP 参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/24.jpg" alt="三次握手优化策略"></p><blockquote><p>客户端的优化</p></blockquote><p>当客户端发起 SYN 包时，可以通过 <code>tcp_syn_retries</code> 控制其重传的次数。</p><blockquote><p>服务端的优化</p></blockquote><p>当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 <code>netstat -s</code> 观察半连接队列溢出的情况，如果 SYN 半连接队列溢出情况比较严重，可以通过 <code>tcp_max_syn_backlog、somaxconn、backlog</code> 参数来调整 SYN 半连接队列的大小。</p><p>服务端回复 SYN+ACK 的重传次数由 <code>tcp_synack_retries</code> 参数控制。如果遭受 SYN 攻击，应把 <code>tcp_syncookies</code> 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。</p><p>服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。</p><p>可以通过 <code>ss -lnt</code> 查看服务端进程的 accept 队列长度，如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 <code>tcp_abort_on_overflow</code> 设置为 1 ，表示用 RST 通知客户端连接建立失败。</p><p>如果 accpet 队列溢出严重，可以通过 listen 函数的 <code>backlog</code> 参数和 <code>somaxconn</code> 系统参数提高队列大小，accept 队列长度取决于 min(backlog, somaxconn)。</p><blockquote><p>绕过三次握手</p></blockquote><p>TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 <code>tcp_fastopen</code> 开启该功能，同时必须保证服务端和客户端同时支持。</p><hr><h2 id="tcp-四次挥手的性能提升" tabindex="-1"><a class="header-anchor" href="#tcp-四次挥手的性能提升" aria-hidden="true">#</a> TCP 四次挥手的性能提升</h2><p>接下来，我们一起看看针对 TCP 四次挥手关闭连接时，如何优化性能。</p><p>在开始之前，我们得先了解四次挥手状态变迁的过程。</p><p>客户端和服务端双方都可以主动断开连接，<strong>通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/25.jpg" alt="客户端主动关闭"></p><p>可以看到，<strong>四次挥手过程只涉及了两种报文，分别是 FIN 和 ACK</strong>：</p><ul><li>FIN 就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；</li><li>ACK 就是确认的意思，用来通知对方：你方的发送通道已经关闭；</li></ul><p>四次挥手的过程:</p><ul><li>当主动方关闭连接时，会发送 FIN 报文，此时发送方的 TCP 连接将从 ESTABLISHED 变成 FIN_WAIT1。</li><li>当被动方收到 FIN 报文后，内核会自动回复 ACK 报文，连接状态将从 ESTABLISHED 变成 CLOSE_WAIT，表示被动方在等待进程调用 close 函数关闭连接。</li><li>当主动方收到这个 ACK 后，连接状态由 FIN_WAIT1 变为 FIN_WAIT2，也就是表示<strong>主动方的发送通道就关闭了</strong>。</li><li>当被动方进入 CLOSE_WAIT 时，被动方还会继续处理数据，等到进程的 read 函数返回 0 后，应用程序就会调用 close 函数，进而触发内核发送 FIN 报文，此时被动方的连接状态变为 LAST_ACK。</li><li>当主动方收到这个 FIN 报文后，内核会回复 ACK 报文给被动方，同时主动方的连接状态由 FIN_WAIT2 变为 TIME_WAIT，<strong>在 Linux 系统下大约等待 1 分钟后，TIME_WAIT 状态的连接才会彻底关闭</strong>。</li><li>当被动方收到最后的 ACK 报文后，<strong>被动方的连接就会关闭</strong>。</li></ul><p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><p>主动关闭方和被动关闭方优化的思路也不同，接下来分别说说如何优化他们。</p><h3 id="主动方的优化" tabindex="-1"><a class="header-anchor" href="#主动方的优化" aria-hidden="true">#</a> 主动方的优化</h3><p>关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。</p><p>如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。</p><p>安全关闭连接的方式必须通过四次挥手，它由进程调用 <code>close</code> 和 <code>shutdown</code> 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。</p><blockquote><p>调用 close 函数和 shutdown 函数有什么区别？</p></blockquote><p>调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong></p><p>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 <code>shutdown</code> 函数，<strong>它可以控制只关闭一个方向的连接</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/26.jpg" alt=""></p><p>第二个参数决定断开连接的方式，主要有以下三种方式：</p><ul><li>SHUT_RD(0)：<strong>关闭连接的「读」这个方向</strong>，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。</li><li>SHUT_WR(1)：<strong>关闭连接的「写」这个方向</strong>，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端。</li><li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，<strong>关闭套接字的读和写两个方向</strong>。</li></ul><p>close 和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数也不相同。</p><blockquote><p>FIN_WAIT1 状态的优化</p></blockquote><p>主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变为 FIN_WAIT2 状态。</p><p>但是当迟迟收不到对方返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，<strong>内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制</strong>（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/27.jpg" alt=""></p><p>你可能会好奇，这 0 表示几次？<strong>实际上当为 0 时，特指 8 次</strong>，从下面的内核源码可知：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/28.jpg" alt=""></p><p>如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。</p><p>对于普遍正常情况时，调低 tcp_orphan_retries 就已经可以了。如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：</p><ul><li>首先，TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文也不能提前发送。</li><li>其次，TCP 有流量控制功能，当接收方接收窗口为 0 时，发送方就不能再发送数据。所以，当攻击者下载大文件时，就可以通过接收窗口设为 0 ，这就会使得 FIN 报文都无法发送出去，那么连接会一直处于 FIN_WAIT1 状态。</li></ul><p>解决这种问题的方法，是<strong>调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/29.jpg" alt=""></p><p>当进程调用了 <code>close</code> 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法再发送和接收数据。Linux 系统为了防止孤儿连接过多，导致系统资源长时间被占用，就提供了 <code>tcp_max_orphans</code> 参数。如果孤儿连接数量大于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。</p><blockquote><p>FIN_WAIT2 状态的优化</p></blockquote><p>当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。</p><p>这时，<strong>如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长</strong>，默认值是 60 秒：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/30.jpg" alt=""></p><p>它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。</p><p>这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的，后面我们再来说说为什么是 60 秒。</p><blockquote><p>TIME_WAIT 状态的优化</p></blockquote><p>TIME_WAIT 是主动方四次挥手的最后一个状态，也是最常遇见的状态。</p><p>当收到被动方发来的 FIN 报文后，主动方会立刻回复 ACK，表示确认对方的发送通道已经关闭，接着就处于 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。</p><p>TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p><p>TIME-WAIT 的状态尤其重要，主要是两个原因：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p><em>原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收</em></p><p>TIME-WAIT 的一个作用是<strong>防止收到历史数据，从而导致数据错乱的问题。</strong></p><p>假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？</p><p><img src="https://img-blog.csdnimg.cn/img_convert/6385cc99500b01ba2ef288c27523c1e7.png" alt="TIME-WAIT 时间过短，收到旧连接的数据报文"></p><ul><li><p>如上图：</p><ul><li>服务端在关闭连接之前发送的 <code>SEQ = 301</code> 报文，被网络延迟了。</li><li>接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 <code>SEQ = 301</code> 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li></ul></li></ul><p>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></p><p><em>原因二：保证「被动关闭连接」的一方，能被正确的关闭</em></p><p>在 RFC 793 指出 TIME-WAIT 另一个重要的作用是：</p><p><em>TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.</em></p><p>也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p><p>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。</p><p>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3a81c23ce57c27cf63fc2b77e34de0ab.png" alt="TIME-WAIT 时间过短，没有确保连接正常关闭"></p><p>服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</p><p>为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/网络/TIME-WAIT连接正常关闭.drawio.png" alt="TIME-WAIT 时间正常，确保了连接正常关闭"></p><p>客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。</p><p>我们再回过头来看看，为什么 TIME_WAIT 状态要保持 60 秒呢？</p><p>这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的原理是一样的，<strong>因为这两个状态都需要保持 2MSL 时长。MSL 全称是 Maximum Segment Lifetime，它定义了一个报文在网络中的最长生存时间</strong>（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。</p><p>为什么是 2 MSL 的时长呢？这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。</p><p>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p><p><strong>因此，TIME_WAIT 和 FIN_WAIT2 状态的最大时长都是 2 MSL，由于在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。</strong></p><blockquote><p>TIME_WAIT 状态优化方式一</p></blockquote><p><strong>Linux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭：</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/33.jpg" alt=""></p><p>当服务器的并发连接增多时，相应地，同时处于 TIME_WAIT 状态的连接数量也会变多，此时就应当调大 <code>tcp_max_tw_buckets</code> 参数，减少不同连接间数据错乱的概率。tcp_max_tw_buckets 也不是越大越好，毕竟系统资源是有限的。</p><blockquote><p>TIME_WAIT 状态优化方式二</p></blockquote><p><strong>有一种方式可以在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。但是需要注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的，而对于服务端（被动连接方）是没有用的。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/34.jpg" alt=""></p><p>网上很多博客都说在服务端开启 tcp_tw_reuse 参数来优化 TCP，我信你个鬼，糟老头坏的很！<strong>tcp_tw_reuse 只作用在 connect 函数，也就是客户端，跟服务端一毛关系的没有</strong>。</p><p>tcp_tw_reuse 从协议角度理解是安全可控的，可以复用处于 TIME_WAIT 的端口为新的连接所用。</p><p>什么是协议角度理解的安全可控呢？主要有两点：</p><ul><li>只适用于连接发起方，也就是 C/S 模型中的客户端；</li><li>对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。</li></ul><p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持（对方也要打开 ）：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/35.jpg" alt=""></p><p>由于引入了时间戳，它能带来了些好处：</p><ul><li>我们在前面提到的 2MSL（TIME_WAIT状态的持续时间） 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；</li><li>同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；</li></ul><p>时间戳是在 TCP 的选项字段里定义的，开启了时间戳功能，在 TCP 报文传输的时候会带上发送报文的时间戳。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/TCP option字段-时间戳.png" alt="TCP option 字段 - 时间戳"></p><p>另外，老版本的 Linux 还提供了 <code>tcp_tw_recycle</code> 参数，但是当开启了它，允许处于 TIME_WAIT 状态的连接被快速回收，但是有个<strong>大坑</strong>。</p><p>开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS（判断TCP 报文中时间戳是否是历史报文） 机制，<strong>per-host 是对「对端 IP 做 PAWS 检查」</strong>，而非对「IP + 端口」四元组做 PAWS 检查。</p><p>如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</p><p>Per-host PAWS 机制利用 TCP option 里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值。</p><p>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，<strong>客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包</strong>。</p><p>因此，tcp_tw_recycle 在使用了 NAT 的网络下是存在问题的，如果它是对 TCP 四元组做 PAWS 检查，而不是对「相同的 IP 做 PAWS 检查」，那么就不会存在这个问题了。</p><p>网上很多博客都说开启 tcp_tw_recycle 参数来优化 TCP，我信你个鬼，糟老头坏的很！</p><p>所以，不建议设置为 1 ，在 Linux 4.12 版本后，Linux 内核直接取消了这一参数，建议关闭它：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/36.jpg" alt=""></p><blockquote><p>TIME_WAIT 状态优化方式三</p></blockquote><p>我们可以在程序中设置 socket 选项，来设置调用 close 关闭连接行为。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/37.jpg" alt=""></p><p>如果 <code>l_onoff</code> 为非 0， 且 <code>l_linger</code> 值为 0，<strong>那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。</strong></p><p>这种方式只推荐在客户端使用，服务端千万不要使用。因为服务端一调用 close，就发送 RST 报文的话，客户端就总是看到 TCP 连接错误 “connnection reset by peer”。</p><h3 id="被动方的优化" tabindex="-1"><a class="header-anchor" href="#被动方的优化" aria-hidden="true">#</a> 被动方的优化</h3><p>当被动方收到 FIN 报文时，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p><p>内核没有权利替代进程去关闭连接，因为如果主动方是通过 shutdown 关闭连接，那么它就是想在半关闭连接上接收数据或发送数据。因此，Linux 并没有限制 CLOSE_WAIT 状态的持续时间。</p><p>当然，大多数应用程序并不使用 shutdown 函数关闭连接。所以，<strong>当你用 netstat 命令发现大量 CLOSE_WAIT 状态。就需要排查你的应用程序，因为可能因为应用程序出现了 Bug，read 函数返回 0 时，没有调用 close 函数。</strong></p><p>处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。</p><p>如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。</p><p>还有一点我们需要注意的，<strong>如果被动方迅速调用 close 函数，那么被动方的 ACK 和 FIN 有可能在一个报文中发送，这样看起来，四次挥手会变成三次挥手，这只是一种特殊情况，不用在意。</strong></p><blockquote><p>如果连接双方同时关闭连接，会怎么样？</p></blockquote><p>由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。</p><p>此时，上面介绍的优化策略仍然适用。两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/38.jpg" alt="同时关闭"></p><p>接下来，<strong>双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态</strong>。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。</p><h3 id="小结-1" tabindex="-1"><a class="header-anchor" href="#小结-1" aria-hidden="true">#</a> 小结</h3><p>针对 TCP 四次挥手的优化，我们需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/39.jpg" alt="四次挥手的优化策略"></p><blockquote><p>主动方的优化</p></blockquote><p>主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 <code>tcp_orphan_retries</code> 参数决定。</p><p>当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：</p><ul><li>如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 <code>tcp_fin_timeout</code> 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，<code>tcp_max_orphans</code> 定义了最大孤儿连接的数量，超过时连接就会直接释放。</li><li>反之是 shutdown 函数关闭的连接，则不受此参数限制；</li></ul><p>当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，<code>tcp_max_tw_buckets</code> 定义了最大数量，超过时连接也会直接释放。</p><p>当 TIME_WAIT 状态过多时，还可以通过设置 <code>tcp_tw_reuse</code> 和 <code>tcp_timestamps</code> 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。</p><blockquote><p>被动方的优化</p></blockquote><p>被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。</p><p>当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 <code>tcp_orphan_retries</code> 参数的控制下重发 FIN 报文。</p><hr><h2 id="tcp-传输数据的性能提升" tabindex="-1"><a class="header-anchor" href="#tcp-传输数据的性能提升" aria-hidden="true">#</a> TCP 传输数据的性能提升</h2><p>在前面介绍的是三次握手和四次挥手的优化策略，接下来主要介绍的是 TCP 传输数据时的优化策略。</p><p>TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：</p><ul><li>如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；</li><li>如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；</li></ul><p>因此，我们必须理解 Linux 下 TCP 内存的用途，才能正确地配置内存大小。</p><h3 id="滑动窗口是如何影响传输速度的" tabindex="-1"><a class="header-anchor" href="#滑动窗口是如何影响传输速度的" aria-hidden="true">#</a> 滑动窗口是如何影响传输速度的？</h3><p>TCP 会保证每一个报文都能够抵达对方，它的机制是这样：报文发出去后，必须接收到对方返回的确认报文 ACK，如果迟迟未收到，就会超时重发该报文，直到收到对方的 ACK 为止。</p><p><strong>所以，TCP 报文发出去后，并不会立马从内存中删除，因为重传时还需要用到它。</strong></p><p>由于 TCP 是内核维护的，所以报文存放在内核缓冲区。如果连接非常多，我们可以通过 free 命令观察到 <code>buff/cache</code> 内存是会增大。</p><p>如果 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句，但这种方式的缺点是效率比较低的。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/40.jpg" alt="按数据包进行确认应答"></p><p>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。</p><p><strong>要解决这一问题不难，并行批量发送报文，再批量确认报文即可。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/41.jpg" alt="并行处理"></p><p>然而，这引出了另一个问题，发送方可以随心所欲的发送报文吗？<strong>当然这不现实，我们还得考虑接收方的处理能力。</strong></p><p>当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。</p><p><strong>为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来。</strong></p><p>接收方根据它的缓冲区，可以计算出后续能够接收多少字节的报文，这个数字叫做接收窗口。当内核接收到报文时，必须用缓冲区存放它们，这样剩余缓冲区空间变小，接收窗口也就变小了；当进程调用 read 函数后，数据被读入了用户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报文，接收窗口就会变大。</p><p>因此，接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的<strong>窗口字段</strong>，这样就可以起到窗口大小通知的作用。</p><p>发送方的窗口等价于接收方的窗口吗？如果不考虑拥塞控制，发送方的窗口大小「约等于」接收方的窗口大小，因为窗口通知报文在网络传输是存在时延的，所以是约等于的关系。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/42.jpg" alt="TCP 头部"></p><p>从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。</p><p>这个窗口大小最大值，在当今高速网络下，很明显是不够用的。所以后续有了扩充窗口的方法：<strong>在 TCP 选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/TCP option字段-窗口.png" alt="TCP option 选项 - 窗口扩展"></p><p>Linux 中打开这一功能，需要把 tcp_window_scaling 配置设为 1（默认打开）：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/43.jpg" alt=""></p><p>要使用窗口扩大选项，通讯双方必须在各自的 SYN 报文中发送这个选项：</p><ul><li>主动建立连接的一方在 SYN 报文中发送这个选项；</li><li>而被动建立连接的一方只有在收到带窗口扩大选项的 SYN 报文之后才能发送这个选项。</li></ul><p>这样看来，只要进程能及时地调用 read 函数读取数据，并且接收缓冲区配置得足够大，那么接收窗口就可以无限地放大，发送方也就无限地提升发送速度。</p><p><strong>这是不可能的，因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。</strong></p><h3 id="如何确定最大传输速度" tabindex="-1"><a class="header-anchor" href="#如何确定最大传输速度" aria-hidden="true">#</a> 如何确定最大传输速度？</h3><p>在前面我们知道了 TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力。其中，窗口大小由内核缓冲区大小决定。如果缓冲区与网络传输能力匹配，那么缓冲区的利用率就达到了最大化。</p><p>问题来了，如何计算网络的传输能力呢？</p><p>相信大家都知道网络是有「带宽」限制的，带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:</p><ul><li>带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；</li><li>缓冲区单位是字节，当网络速度乘以时间才能得到字节数；</li></ul><p>这里需要说一个概念，就是带宽时延积，它决定网络中飞行报文的大小，它的计算方式：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/44.jpg" alt=""></p><p>比如最大带宽是 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节。</p><p>这个 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为 BDP，Bandwidth Delay Product）。同时，这 1MB 也表示「飞行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1 MB，就会导致网络过载，容易丢包。</p><p><strong>由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。</strong></p><p>发送缓冲区与带宽时延积的关系：</p><ul><li>如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；</li><li>如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。</li></ul><p>所以，发送缓冲区的大小最好是往带宽时延积靠近。</p><h3 id="怎样调整缓冲区大小" tabindex="-1"><a class="header-anchor" href="#怎样调整缓冲区大小" aria-hidden="true">#</a> 怎样调整缓冲区大小？</h3><p>在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行<strong>动态调节</strong>。</p><blockquote><p>调节发送缓冲区范围</p></blockquote><p>先来看看发送缓冲区，它的范围通过 tcp_wmem 参数配置；</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/45.jpg" alt=""></p><p>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，4096 byte = 4K；</li><li>第二个数值是初始默认值，16384 byte ≈ 16K；</li><li>第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；</li></ul><p><strong>发送缓冲区是自行调节的</strong>，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。</p><blockquote><p>调节接收缓冲区范围</p></blockquote><p>而接收缓冲区的调整就比较复杂一些，先来看看设置接收缓冲区范围的 tcp_rmem 参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/46.jpg" alt=""></p><p>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4096 byte = 4K；</li><li>第二个数值是初始默认值，87380 byte ≈ 86K；</li><li>第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；</li></ul><p><strong>接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：</strong></p><ul><li>如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；</li><li>反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；</li></ul><p>发送缓冲区的调节功能是自动开启的，<strong>而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/47.jpg" alt=""></p><blockquote><p>调节 TCP 内存范围</p></blockquote><p>接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/48.jpg" alt=""></p><p>上面三个数字单位不是字节，而是「页面大小」，1 页表示 4KB，它们分别表示：</p><ul><li>当 TCP 内存小于第 1 个值时，不需要进行自动调节；</li><li>在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；</li><li>大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；</li></ul><p>一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 tcp_mem 最大内存页面数是 177120，当内存为 (177120 * 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP 连接分配内存，即 TCP 连接将被拒绝。</p><blockquote><p>根据实际场景调节的策略</p></blockquote><p>在高并发服务器中，为了兼顾网速与大量的并发连接，<strong>我们应当保证缓冲区的动态调整的最大值达到带宽时延积，而最小值保持默认的 4K 不变即可。而对于内存紧张的服务而言，调低默认值是提高并发的有效手段。</strong></p><p>同时，如果这是网络 IO 型服务器，那么，<strong>调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存，这有利于提升并发能力</strong>。需要注意的是，tcp_wmem 和 tcp_rmem 的单位是字节，而 tcp_mem 的单位是页面大小。而且，<strong>千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF，这样会关闭缓冲区的动态调整功能。</strong></p><h3 id="小结-2" tabindex="-1"><a class="header-anchor" href="#小结-2" aria-hidden="true">#</a> 小结</h3><p>本节针对 TCP 优化数据传输的方式，做了一些介绍。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/计算机网络/TCP-参数/49.jpg" alt="数据传输的优化策略"></p><p>TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。</p><p>可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 <code>tcp_window_scaling</code> 为 1 做到的，此时最大值可高达 1GB。</p><p>滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。</p><p>内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。</p><p>Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。</p><p>但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。</p><p>有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。</p><hr><p>参考资料：</p><p>[1] 系统性能调优必知必会.陶辉.极客时间.</p><p>[2] 网络编程实战专栏.盛延敏.极客时间.</p><p>[3] http://www.blogjava.net/yongboy/archive/2013/04/11/397677.html</p><p>[4] http://blog.itpub.net/31559359/viewspace-2284113/</p><p>[5] https://blog.51cto.com/professor/1909022</p><p>[6] https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux</p><hr><h2 id="读者问答" tabindex="-1"><a class="header-anchor" href="#读者问答" aria-hidden="true">#</a> 读者问答</h2><blockquote><p>读者问：“涵宇，请教个问题，somaxconn和backlog是不是都是指的是accept队列？然后somaxconn是内核参数，backlog是通过系统调用间隔地修改somaxconn，比如Linux中listen()函数？”</p></blockquote><p>两者取最小值才是 accpet 队列。</p><blockquote><p>读者问：“涵宇，还有个问题要请教下，“如果 accept 队列满了，那么 server 扔掉 client 发过来的 ack”，也就是说该TCP连接还是位于半连接队列中，没有丢弃吗？”</p></blockquote><ol><li>当 accept 队列满了，后续新进来的syn包都会被丢失</li><li>我文章的突发流量例子是，那个连接进来的时候 accept 队列还没满，但是在第三次握手的时候，accept 队列突然满了，就会导致 ack 被丢弃，就一直处于半连接队列。</li></ol><hr></div><!--[--><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 1453300745@qq.com">wangtao</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/assets/app.10857eea.js" defer></script>
  </body>
</html>
